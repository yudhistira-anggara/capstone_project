{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tranfer learning project\n",
    "- the purpose of this notebook is to improve our performace models. this is intended to get around the limitations of availablecomputing resources. due to we can training model in heavy computation gradually\n",
    "- for the procces we will use pretraining models that from the previous training model. \n",
    "- previous model is not have much layer, but process need heavy computation resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-84efd1d66adf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# function for laod model\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "# keras layers\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models.optimizers import Adam\n",
    "# preprocessing gambar\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  first way, load thw weight model in hdp5 (model.h5)\n",
    "if you save your architecture model and model weight  in one file that have extention .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(#pass the save model wight) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second way, load json file and weight file \n",
    "if you save your model architecture and model weight separately you can use this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path= # pass file json here\n",
    "with open(json_file,\"r\") as file:\n",
    "    model=model_from_json(file.read())\n",
    "    model.load_weight\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore the pre training model \n",
    "- you can explore layers, and imput shape then you can determine the next strategi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this model have 3 convolutional layers, 1 layer dropout , 1 layer flatten dan 2 layer dense. dengan demikian, kita hanya perlu 4 layer pertama dan 3 layer akan dibuat baru  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tuning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    model.layers[i].trainable= True\n",
    "    \n",
    "num_classes=10  \n",
    "ll = model.layers[4].output\n",
    "l1 = Flatten()(l1)\n",
    "ll = Dense(512, activation=\"relu\")(ll)\n",
    "ll = Dense(num_classes,activation=\"softmax\")(ll)\n",
    "\n",
    "new_model = Model(inputs=model.input,outputs=ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### explore and compile the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model \n",
    "new_model.summary()\n",
    "# compile model\n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer= Adam(learning_rate=0.00001), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing dataset\n",
    "- dataset that using is same with the previous models that is model from dermnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=#pass path of train directory\n",
    "train_dir=os.path.join(dataset_dir,\"train\")\n",
    "test_dir= os.path.join(dataset_dr,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "IMAGE_SIZE=360\n",
    "train_datagen= ImageDataGenerator(rescale=1/255,\n",
    "                                  rotation_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode=\"nearest\",)\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                                  target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                  class_mode=\"categorcal\",\n",
    "                                                  batch_size=BATCH_SIZE,)\n",
    "test_datagen= ImageDataGenerator(rescale=1/255)\n",
    "test_generator= test_datagen.flow_from_dirctory(test_dir,\n",
    "                                                target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                   ,)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
