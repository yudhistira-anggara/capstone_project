{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tranfer learning project\n",
    "- the purpose of this notebook is to improve our performace models. this is intended to get around the limitations of availablecomputing resources. due to we can training model in heavy computation gradually in other word, this note book for check point perkembangan model\n",
    "- for the procces we will use pretraining models that from the previous training model. \n",
    "- previous model is not have much layer, but process need heavy computation resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os\n",
    "import os\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# function for laod model\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "# keras layers\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "# preprocessing gambar\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#ploting performace\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  first way, load the weight model in hdp5 (model.h5)\n",
    "if you save your architecture model and model weight  in one file that have extention .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_model = load_model(#pass the save model wight) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second way, load json file and weight file \n",
    "if you save your model architecture and model weight separately you can use this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path= # pass file json here\n",
    "with open(json_file,\"r\") as file:\n",
    "    pre_train_model=model_from_json(file.read())\n",
    "    pre_train_model.load_weight\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore the pre training model \n",
    "- you can explore layers, and imput shape then you can determine the next strategi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this model have 3 convolutional layers, 1 layer dropout , 1 layer flatten dan 2 layer dense. dengan demikian, kita hanya perlu 4 layer pertama dan 3 layer akan dibuat baru  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tuning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    pre_train_model.layers[i].trainable= True\n",
    "    \n",
    "num_classes=10  \n",
    "ll = pre_train_model.layers[4].output\n",
    "l1 = Flatten()(l1)\n",
    "ll = Dense(512, activation=\"relu\")(ll)\n",
    "ll = Dense(num_classes,activation=\"softmax\")(ll)\n",
    "\n",
    "model = Model(inputs=model.input,outputs=ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### explore and compile the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model \n",
    "model.summary()\n",
    "# compile model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= Adam(learning_rate=0.00001), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing dataset\n",
    "- dataset that using is same with the previous models that is model from dermnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=#pass path of train directory\n",
    "train_dir=os.path.join(dataset_dir,\"train\")\n",
    "test_dir= os.path.join(dataset_dr,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "IMAGE_SIZE=360\n",
    "train_datagen= ImageDataGenerator(rescale=1/255,\n",
    "                                  rotation_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode=\"nearest\",)\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                                  target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                  class_mode=\"categorcal\",\n",
    "                                                  batch_size=BATCH_SIZE,)\n",
    "test_datagen= ImageDataGenerator(rescale=1/255)\n",
    "test_generator= test_datagen.flow_from_dirctory(test_dir,\n",
    "                                                target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                   suffle=True,\n",
    "                                                                   image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                   batch_size= BATCH_SIZE)\n",
    "test_dataset= tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                 suffle=True,\n",
    "                                                                 image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                 batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_weights(class_series):\n",
    "    class_labels = np.unique(class_series)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=class_series)\n",
    "    return dict(zip(class_labels, class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "class_names= train_genetaror.class_indices\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts= [len(os.listdir(os.path.join(train_dir,label))) for label in labels]\n",
    "train_dict=dict(zip(labels,counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "use_label = heapq.nlargest(10, train_dict, key=test_dict.get)\n",
    "train_labels = [class_names[key] for key in train_dict for val in range(train_dict[key])]\n",
    "class_weight = generate_class_weights(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n",
    "history= model.fit(train_generator,epochs=10, validation=train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_plot(history):\n",
    "    accuracy= hstory.history[\"accuracy\"]\n",
    "    validation_accuracy= history.history[\"val_accuracy\"]\n",
    "    loss= history.history[\"loss\"]\n",
    "    validation= history.history[\"val_loss\"]\n",
    "    \n",
    "    epochs= range(len(accuracy))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs,accuracy, \"r\", label= \"accuracy\")\n",
    "    plt.plot(epochs,validation_accuracy, \"b\", label=\"accuracy\")\n",
    "    plt.tittle(\"accuracy model\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs,loss,\"r\",label=\"loss\")\n",
    "    plt.plot(epochhs,loss,\"b\", label=\"loss validasi\")\n",
    "    plt.tittle(\" models loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model in json file and h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json file\n",
    "model_json= model.to_json()\n",
    "with open(\"saved_model.json\",\"w\") as file:\n",
    "    file.write(model_json)\n",
    "model.save_weights(\"save_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert and save tensorflow lite file \n",
    "- if you satisfy with the last performance of the model, you can convert and download tensorflow lite to deploy it in android app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir= \" save_model/1\"\n",
    "tf.saved_model.save(model,export_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $RPS_SAVED_MODEL\n",
    "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(RPS_SAVED_MODEL)\n",
    "print(list(loaded.signatures.keys()))\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_input_signature)\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_file = 'converted_model.tflite'\n",
    "with open(tflite_model_file, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.txt', 'w') as f:\n",
    "    f.write('\\n'.join(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('converted_model.tflite')\n",
    "    files.download('labels.txt')\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
