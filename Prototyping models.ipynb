{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yuira34/capstone_project/blob/main/capstone_project_A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prototyping machine learning project from Dernmnet dataset\n",
    "this note book use for make prototype model to deterrmine the best model architecture. dataset that using from kaggle.com \n",
    "this notebook design for running in google colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download dataset\n",
    "to download data, ensure that you install kaggle libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cBit9e7g3DM",
    "outputId": "4c02af50-8398-4b3b-9a2f-f975090c165d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "#terlebih dahulu untuk mendownload kaggle.json melalui kaggle.com\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "# copy API download dataset command  di dataset kagle, kemudian paste di sini\n",
    "!kaggle datasets download -d shubhamgoel27/dermnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for extract and pre precessing data\n",
    "import os, zipfile\n",
    "# libraries for machine learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizer import RMSprop\n",
    "#libraries for preprocessing data\n",
    "from tensorflow.keras.preprocessing import ImageDataGenerator\n",
    "#libraries for \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract dataset and split it into train and test \n",
    "dermnet.zip already  split into train and test directoy, so it just need to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qn1s5DbpjdcO"
   },
   "outputs": [],
   "source": [
    "local_zip = \"/content/dermnet.zip\"\n",
    "extract_dir = \"/content/dermnet_dataset\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(extract_dir)\n",
    "zip_ref.close()\n",
    "\n",
    "train_dir= os.path.join(extract_dir,\"train\")\n",
    "test_dir= os.path.join(extract_dir,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RksTZQCJn8dp"
   },
   "source": [
    "## build model architecture\n",
    "it will make a few different model architecture and combination layers that will train then see the performance evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=tf.keras.models.Sequential([tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(300,300,3)),#edit sesuai dengan ukuran target),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   tf.keras.layers.Conv2D(128,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   tf.keras.layers.Conv2D(256,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   tf.keras.layers.Conv2D(256,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   tf.keras.layers.Flatten(),\n",
    "                                   tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "                                   tf.keras.layers.Dense(23,activation=\"softmax\")\n",
    "                                   \n",
    "                                  ])\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"ADAM\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing data\n",
    "it will process the raw data so that can use for data training. we will use class ImageDataGenerator and flow_from_directory() method. and include augmentation( rescale, sheer, zoom, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255,\n",
    "                                 rotate_range=1,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0,4\n",
    "                                 horizontal_flip=True,\n",
    "                                 fill_mode=\"nearest\",)\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                                  target_size=()#edit disini)\n",
    "                                                  batch_size=32)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_generator= test_datagen.flow_from_directory(test_dir,\n",
    "                                                 target_size=()#edit disini\n",
    "                                                 batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train\n",
    "train each model above with the same parameter \n",
    "* step_per_epoch= 10\n",
    "* epoch = 100\n",
    "* batch = 32\n",
    "* verbose= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1=model1.fit(train_generator,step_per_epoch=10,epochs=100,verbose=1,validation_data=test_generator,batch=32,validation_steps=10)#fill parameter here)\n",
    "# history2=model2.fit(#fill parameter here)\n",
    "# history3=model3.fit(#fill parameter here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build function for plot the peformace per epoch \n",
    "function perform_plot will plot the performance per epoch then will passed by history then it will reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_plot(history):\n",
    "    #edit here\n",
    "    \"\"\"\n",
    "    this function use for plot model performance i.e loss and accuracy from train and validation data\n",
    "    this plot will used for evaluate model performance and check overfitting\n",
    "    \"\"\"\n",
    "    #plot the model result\n",
    "    accuracy=history.history['accuracy']\n",
    "    validation_accuracy=history.history['val_accuracy']\n",
    "    loss= history.history['loss']\n",
    "    validation_loss=history.history['val_loss']\n",
    "    \n",
    "    epoch=range(len(accuracy))\n",
    "    \n",
    "    #plot accuracy\n",
    "    plt.plot(epoch,accuracy,'r',label=\"Training accuracy\")\n",
    "    plt.plot(epoch,validation_accuracy,'b',label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and Validation accuracy\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epoch,loss,'r',label=\"Training loss\")\n",
    "    plt.plot(epoch,validation_loss,'b', label=\"Validation loss\")\n",
    "    plt.title(\"training and validation loss\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate each model\n",
    "plot the models performance then evaluate the best model. and make sure that validation accuracy greater than 80. if not, make a new model architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history= [ histori1, history2.....]\n",
    "#for hist in history:\n",
    "#   perform_plot(hist)\n",
    "#   plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save wight and bin file from the best model\n",
    "this bin and wight file will used for next process in this project( tranfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyObinCX1ecvlSHex4IR56eX",
   "include_colab_link": true,
   "mount_file_id": "1gnOjckk-bvwsk8TrhWhJst4Kz4RTWpQm",
   "name": "capstone_project_A0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
