{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yuira34/capstone_project/blob/main/capstone_project_A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prototyping machine learning project from Dermnet dataset\n",
    "this note book use for make prototype model to deterrmine the best model architecture. dataset that using from kaggle.com \n",
    "this notebook design for running in google colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### description of dataset \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### purpose of the notebook\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download dataset\n",
    "to download data, ensure that you install kaggle libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cBit9e7g3DM",
    "outputId": "4c02af50-8398-4b3b-9a2f-f975090c165d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "Requirement already satisfied: six>=1.10 in d:\\anaconda\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\lib\\site-packages (from kaggle) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil in d:\\anaconda\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from kaggle) (2.24.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from kaggle) (4.50.2)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in d:\\anaconda\\lib\\site-packages (from kaggle) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73057 sha256=e8e97c1a1bcd981a42856b85237d78f65bcff2a4213b5a1787be749a3a9f918c\n",
      "  Stored in directory: c:\\users\\cacc\\appdata\\local\\pip\\cache\\wheels\\29\\da\\11\\144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-6.1.2 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install kaggle\n",
    "#terlebih dahulu untuk mendownload kaggle.json melalui kaggle.com\n",
    "#!cp ~/content/kaggle.json ~/.kaggle/\n",
    "#!chmod 600 ~/.kaggle/kaggle.json\n",
    "# copy API download dataset command  di dataset kagle, kemudian paste di sini\n",
    "!kaggle datasets download -d shubhamgoel27/dermnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset yang lain \n",
    "#!kaggle datasets download -d paoloripamonti/derma-diseases\n",
    "#https://www.kaggle.com/datasets/paoloripamonti/derma-diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for extract and pre precessing data\n",
    "import os, zipfile, PIL\n",
    "# libraries for machine learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "#libraries for preprocessing data\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#libraries for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# libraries for save data\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract dataset and split it into train and test \n",
    "dermnet.zip already  split into train and test directoy, so it just need to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qn1s5DbpjdcO"
   },
   "outputs": [],
   "source": [
    "local_zip = \"/content/dermnet.zip\"\n",
    "extract_dir = \"/content/dermnet_dataset\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(extract_dir)\n",
    "zip_ref.close()\n",
    "\n",
    "train_dir= os.path.join(extract_dir,\"train\")\n",
    "test_dir= os.path.join(extract_dir,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data and image exploration\n",
    "to explore feature of the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, and number sample each label exploration\n",
    "labels= os.listdir(train_dir)\n",
    "print(\" the model has {} labels with is \\n\".format(len(labels)))\n",
    "for nomor, label in enumerate(labels):\n",
    "    print(\"{} {} have {} train data samples and {} test data samples\".format(nomor, \n",
    "                                                                             label, \n",
    "                                                                             len(os.listdir(os.path.join(train_dir,label))),\n",
    "                                                                             len(os.listdir(os.path.join(test_dir,label)))\n",
    "                                                                            )\n",
    "         )\n",
    "# image exploration\n",
    "\n",
    "image_samp_dir=[os.path.join(train_dir,label) for label in labels[:5]]\n",
    "for dir_ in image_sample_dir:\n",
    "    for img in os.listdir(dir_)[:2]:\n",
    "        im= PIL.Image.open(os.path.join(dir_, img))# pass with the picture directory\n",
    "        print(\"image \\n format :{},size: {} , color: {} \\n\".format(im.format,im.size,im.mode))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing data\n",
    "it will process the raw data so that can use for data training. we will use class ImageDataGenerator and flow_from_directory() method. and include augmentation( rescale, sheer, zoom, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 720\n",
    "train_datagen=ImageDataGenerator(rescale=1/255,\n",
    "                                 rotation_range=40,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True,\n",
    "                                 fill_mode=\"nearest\"\n",
    "                                )\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                                  target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                  class_mode=\"categorical\",#edit disini)\n",
    "                                                  batch_size=BATCH_SIZE\n",
    "                                                 )\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_generator= test_datagen.flow_from_directory( train_dir,\n",
    "                                                  target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                  class_mode=\"categorical\",#edit disini)\n",
    "                                                  batch_size=BATCH_SIZE\n",
    "                                                )\n",
    "#ploting versi image generator\n",
    "for _ in range(5):\n",
    "    img, label = train_generator.next()\n",
    "    print(img.shape)   #  (1,256,256,3)\n",
    "    print(label[0])\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                    shuffle = True,\n",
    "                                                                    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                    batch_size = BATCH_SIZE \n",
    "                                                                   )\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                   shuffle = True,\n",
    "                                                                   image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                   batch_size = BATCH_SIZE  \n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class names pakek image generator\n",
    "class_names = train_generator.class_indices\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "for image_batch, label_batch in train_dataset.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3,4,i+1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[label_batch[i]],fontsize = 8)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RksTZQCJn8dp"
   },
   "source": [
    "## build model architecture\n",
    "it will make a few different model architecture and combination layers that will train then see the performance evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                                    \n",
    "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    \n",
    "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    \n",
    "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(len, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=Adam(learning_rate=0.0001),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=tf.keras.models.Sequential([tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(224,224,3)),#edit sesuai dengan ukuran target),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #2\n",
    "                                   tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #3\n",
    "                                   tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #4\n",
    "                                   tf.keras.layers.Conv2D(128,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #5\n",
    "                                   tf.keras.layers.Conv2D(256,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #6\n",
    "                                   tf.keras.layers.Conv2D(512,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   # dropout layers\n",
    "                                   tf.keras.layers.Dropout(0.2),\n",
    "                                   #dense\n",
    "                                   tf.keras.layers.Flatten(),\n",
    "                                   tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "                                   tf.keras.layers.Dense(len(class_names),activation=\"softmax\")\n",
    "                                   \n",
    "                                  ])\n",
    "model1.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=tf.keras.models.Sequential([tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(224,224,3)),#edit sesuai dengan ukuran target),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #2\n",
    "                                   tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #3\n",
    "                                   tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #4\n",
    "                                   tf.keras.layers.Conv2D(128,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #5\n",
    "                                   tf.keras.layers.Conv2D(256,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   #6\n",
    "                                   tf.keras.layers.Conv2D(512,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   # dropout layers\n",
    "                                   tf.keras.layers.Dropout(0.2),\n",
    "                                   #dense\n",
    "                                   tf.keras.layers.Flatten(),\n",
    "                                   tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "                                   tf.keras.layers.Dense(23,activation=\"softmax\")\n",
    "                                   \n",
    "                                  ])\n",
    "model1.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3= tf.keras.models.Sequential([tf.keras.layers.Conv2D(64,(18,18), activation=\"relu\",input_shape=(720,480,1)),\n",
    "                                    tf.keras.layers.MaxPooling2D(8,8),\n",
    "                                    #2 \n",
    "                                    tf.keras.layers.Conv2D(64,(18,18),activation=\"relu\"),\n",
    "                                    tf.keras.layers.MaxPooling2D(8,8),\n",
    "                                    #3\n",
    "                                   tf.keras.layers.Conv2D(64,(18,18),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(4,4),\n",
    "                                   #4\n",
    "                                   tf.keras.layers.Conv2D(128,(9,9),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(4,4),\n",
    "                                   #5\n",
    "                                   tf.keras.layers.Conv2D(256,(9,9),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(4,4),\n",
    "                                   #6\n",
    "                                   tf.keras.layers.Conv2D(512,(3,3),activation=\"relu\"),\n",
    "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                   # dropout layers\n",
    "                                   tf.keras.layers.Dropout(0.2),\n",
    "                                   #dense\n",
    "                                   tf.keras.layers.Flatten(),\n",
    "                                   tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "                                   tf.keras.layers.Dense(23,activation=\"softmax\")\n",
    "                                   ])\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizers=Adam(learning_rate=0.00001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train\n",
    "train each model above with the same parameter \n",
    "* step_per_epoch= 10\n",
    "* epoch = 100\n",
    "* batch = 32\n",
    "* verbose= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_generator,\n",
    "                  epochs=100,\n",
    "                  validation_data=test_generator)\n",
    "#history1=model1.fit(train_generator,\n",
    " #                   steps_per_epoch=10,\n",
    "#                    epochs=100,\n",
    " #                   verbose=1,\n",
    "  #                  validation_data=test_generator,\n",
    "   #                 validation_steps=10)#fill parameter here)\n",
    "#history2=model2.fit(train_generator,\n",
    " #                   steps_per_epoch=10,\n",
    "  #                  epochs=100,\n",
    "   #                 verbose=1,\n",
    "    #                validation_data=test_generator,\n",
    "     #               validation_steps=10)#fill parameter here)\n",
    "\n",
    "# history3=model3.fit(#fill parameter here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build function for plot the peformace per epoch \n",
    "function perform_plot will plot the performance per epoch then will passed by history then it will reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_plot(history):\n",
    "    #edit here\n",
    "    \"\"\"\n",
    "    this function use for plot model performance i.e loss and accuracy from train and validation data\n",
    "    this plot will used for evaluate model performance and check overfitting\n",
    "    \"\"\"\n",
    "    #plot the model result\n",
    "    accuracy=history.history['accuracy']\n",
    "    validation_accuracy=history.history['val_accuracy']\n",
    "    loss= history.history['loss']\n",
    "    validation_loss=history.history['val_loss']\n",
    "    \n",
    "    epoch=range(len(accuracy))\n",
    "    \n",
    "    #plot accuracy\n",
    "    plt.plot(epoch,accuracy,'r',label=\"Training accuracy\")\n",
    "    plt.plot(epoch,validation_accuracy,'b',label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and Validation accuracy\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epoch,loss,'r',label=\"Training loss\")\n",
    "    plt.plot(epoch,validation_loss,'b', label=\"Validation loss\")\n",
    "    plt.title(\"training and validation loss\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate each model\n",
    "plot the models performance then evaluate the best model. and make sure that validation accuracy greater than 80. if not, make a new model architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history= [ history1, history2]\n",
    "#for hist in history:\n",
    " #   perform_plot(hist)\n",
    "  #  plt.figure()\n",
    "perform_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save weight and bin file from the best model\n",
    "this bin and wight file will used for next process in this project( tranfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save models, convert to tf.lite, and save tf lite model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export the save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "export_dir = 'saved_model/1'# edit jadi path drive\n",
    "tf.saved_model.save(model, export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $RPS_SAVED_MODEL\n",
    "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(RPS_SAVED_MODEL)\n",
    "print(list(loaded.signatures.keys()))\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_input_signature)\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert model to tensorflow lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tensorflow lite model\n",
    "#tflite_model_file = pathlib.Path('model.tflite')\n",
    "#tflite_model_file.write_bytes(tflite_model)\n",
    "tflite_model_file = 'converted_model.tflite'\n",
    "\n",
    "with open(tflite_model_file, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the TFLite Model Using the Python Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "with open(tflite_model_file, 'rb') as fid:\n",
    "    tflite_model = fid.read()\n",
    "    \n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "test_labels, test_imgs = [], []\n",
    "for img, label in tqdm(test_batches.take(10)):\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_index))\n",
    "    \n",
    "    test_labels.append(label.numpy()[0])\n",
    "    test_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Utility functions for plotting\n",
    "# Utilities for plotting\n",
    "\n",
    "class_names = labels\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    img = np.squeeze(img)\n",
    "    \n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    print(type(predicted_label), type(true_label))\n",
    "    \n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "        \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]), color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Visualize the outputs { run: \"auto\" }\n",
    "index = 0 #@param {type:\"slider\", min:0, max:9, step:1}\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(index, predictions, test_labels, test_imgs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create fie for save labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.txt', 'w') as f:\n",
    "    f.write('\\n'.join(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('converted_model.tflite')\n",
    "    files.download('labels.txt')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Test Images for Download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for index, (image, label) in enumerate(test_batches.take(50)):\n",
    "    image = tf.cast(image * 255.0, tf.uint8)\n",
    "    image = tf.squeeze(image).numpy()\n",
    "    pil_image = Image.fromarray(image)\n",
    "    pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]], index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls test_images\n",
    "!zip -qq rps_test_images.zip -r test_images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    files.download('rps_test_images.zip')\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyObinCX1ecvlSHex4IR56eX",
   "include_colab_link": true,
   "mount_file_id": "1gnOjckk-bvwsk8TrhWhJst4Kz4RTWpQm",
   "name": "capstone_project_A0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
